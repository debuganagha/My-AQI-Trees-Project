{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('PA_metadata_train-1.csv')\n",
    "df2 = pd.read_csv('PA_metadata_train-2.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lon        lat    year  geoUncertaintyInM  areaInM2         region  \\\n",
      "0  3.099038  43.134956  2021.0                5.0     100.0  MEDITERRANEAN   \n",
      "1  3.099038  43.134956  2021.0                5.0     100.0  MEDITERRANEAN   \n",
      "2  3.099038  43.134956  2021.0                5.0     100.0  MEDITERRANEAN   \n",
      "3  3.099038  43.134956  2021.0                5.0     100.0  MEDITERRANEAN   \n",
      "4  3.099038  43.134956  2021.0                5.0     100.0  MEDITERRANEAN   \n",
      "\n",
      "  country  speciesId  surveyId                county  ... 55.33177  2019  \\\n",
      "0  France     6874.0     212.0  Languedoc-Roussillon  ...      NaN   NaN   \n",
      "1  France      476.0     212.0  Languedoc-Roussillon  ...      NaN   NaN   \n",
      "2  France    11157.0     212.0  Languedoc-Roussillon  ...      NaN   NaN   \n",
      "3  France     8784.0     212.0  Languedoc-Roussillon  ...      NaN   NaN   \n",
      "4  France     4530.0     212.0  Languedoc-Roussillon  ...      NaN   NaN   \n",
      "\n",
      "   10.0  79.0  CONTINENTAL  Denmark 7661 1976273  Zealand  Naestved Kommune  \n",
      "0   NaN   NaN          NaN      NaN  NaN     NaN      NaN               NaN  \n",
      "1   NaN   NaN          NaN      NaN  NaN     NaN      NaN               NaN  \n",
      "2   NaN   NaN          NaN      NaN  NaN     NaN      NaN               NaN  \n",
      "3   NaN   NaN          NaN      NaN  NaN     NaN      NaN               NaN  \n",
      "4   NaN   NaN          NaN      NaN  NaN     NaN      NaN               NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lon', 'lat', 'year', 'geoUncertaintyInM', 'areaInM2', 'region',\n",
      "       'country', 'speciesId', 'surveyId', 'county', 'district'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        lon        lat  year  speciesId\n",
      "0  3.099038  43.134956  2021       6874\n",
      "1  3.099038  43.134956  2021        476\n",
      "2  3.099038  43.134956  2021      11157\n",
      "3  3.099038  43.134956  2021       8784\n",
      "4  3.099038  43.134956  2021       4530\n"
     ]
    }
   ],
   "source": [
    "df = df[['lon', 'lat', 'year', 'speciesId']]\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               lon        lat  year  speciesId\n",
      "0         3.099038  43.134956  2021       6874\n",
      "2780      4.177610  43.848390  2017       6874\n",
      "3112     15.485710  42.110800  2020       6874\n",
      "3554      2.339040  43.145010  2018       6874\n",
      "4185      5.486416  43.204942  2019       6874\n",
      "...            ...        ...   ...        ...\n",
      "1471906   3.144531  43.194955  2021       6874\n",
      "1471946   9.374250  40.938296  2018       6874\n",
      "1476908   5.672178  43.214294  2021       6874\n",
      "1478750   2.878387  43.047919  2021       6874\n",
      "1479381   9.277770  42.613390  2017       6874\n",
      "\n",
      "[924 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "species_6874_rows = df[df['speciesId'] == 6874]\n",
    "\n",
    "print(species_6874_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a GeoDataFrame from the dataset\n",
    "geometry = gpd.points_from_xy(df['lon'], df['lat'])\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "# Plot all points with a single marker\n",
    "gdf.plot(ax=ax, marker='o', color='blue', markersize=5)  # Use 'o' marker in blue color\n",
    "\n",
    "# Add a grid to the plot\n",
    "ax.grid(True, linestyle='--', alpha=0.5)  # Customize grid style and transparency\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Tree Distribution\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.15255222915197517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Take a random sample of your DataFrame if it's too large\n",
    "sample_size = 1000  # Adjust as needed\n",
    "df_sampled = df.sample(n=sample_size, random_state=1)  # Use a random seed for reproducibility\n",
    "\n",
    "# Compute silhouette score on the sampled data\n",
    "if -1 in df_sampled['cluster'].values:\n",
    "    valid_clusters = df_sampled[df_sampled['cluster'] != -1]\n",
    "else:\n",
    "    valid_clusters = df_sampled\n",
    "\n",
    "silhouette_avg = silhouette_score(valid_clusters[['lon', 'lat']], valid_clusters['cluster'])\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "# Plot the cluster centroids\n",
    "ax.scatter(average_coordinates['lon'], average_coordinates['lat'], \n",
    "           c='red', marker='X', s=10, label='Cluster Centroids')  # 'X' marker for centroids\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\"Cluster Centroids of Tree Data\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)  # Add a grid for reference\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from scipy.spatial import ConvexHull\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming df is your DataFrame containing 'lon', 'lat', and 'speciesId'\n",
    "# # Prepare the data for clustering\n",
    "# coordinates = df[['lon', 'lat']].values\n",
    "\n",
    "# # Apply DBSCAN\n",
    "# dbscan = DBSCAN(eps=0.005, min_samples=5)  # Adjust eps based on your data density\n",
    "# df['cluster'] = dbscan.fit_predict(coordinates)\n",
    "\n",
    "# # Create a GeoDataFrame from the dataset\n",
    "# geometry = gpd.points_from_xy(df['lon'], df['lat'])\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# # Set up the plot\n",
    "# fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# # Plot all points with a single marker\n",
    "# gdf.plot(ax=ax, marker='o', color='blue', markersize=5, label='Trees')  # Use 'o' marker in blue color\n",
    "\n",
    "# # Plot cluster boundaries\n",
    "# for cluster_id in gdf['cluster'].unique():\n",
    "#     if cluster_id != -1:  # Skip noise points\n",
    "#         cluster_points = gdf[gdf['cluster'] == cluster_id]\n",
    "#         if len(cluster_points) >= 3:  # Need at least three points to form a convex hull\n",
    "#             hull = ConvexHull(cluster_points[['lon', 'lat']].values)\n",
    "#             hull_points = np.append(hull.vertices, hull.vertices[0])  # Close the polygon\n",
    "#             ax.plot(cluster_points.iloc[hull_points]['lon'], \n",
    "#                     cluster_points.iloc[hull_points]['lat'], \n",
    "#                     color='red', alpha=0.5)  # Draw the boundary in red\n",
    "\n",
    "# # Add a grid to the plot\n",
    "# ax.grid(True, linestyle='--', alpha=0.5)  # Customize grid style and transparency\n",
    "\n",
    "# # Customize the plot\n",
    "# plt.title(\"Tree Distribution with Cluster Boundaries\")\n",
    "# plt.xlabel(\"Longitude\")\n",
    "# plt.ylabel(\"Latitude\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# OpenWeatherMap API credentials\n",
    "api_key = \"00e8e808c9ee63e1a6848d838daabe6d\"\n",
    "\n",
    "# Function to get all air pollution components from OpenWeatherMap for given lat and lon\n",
    "def get_air_pollution_data(lat, lon):\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/air_pollution?lat={lat}&lon={lon}&appid={api_key}\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()  # Parse the response to JSON\n",
    "            main_aqi = data['list'][0]['main']['aqi']  # AQI value\n",
    "            \n",
    "            components = data['list'][0]['components']  # All pollutant components\n",
    "            co2 = components.get('co2', None)\n",
    "            co = components.get('co', None)       # Carbon Monoxide\n",
    "            no = components.get('no', None)       # Nitric Oxide\n",
    "            no2 = components.get('no2', None)     # Nitrogen Dioxide\n",
    "            o3 = components.get('o3', None)       # Ozone\n",
    "            so2 = components.get('so2', None)     # Sulfur Dioxide\n",
    "            pm25 = components.get('pm2_5', None)  # Fine Particulate Matter (PM2.5)\n",
    "            pm10 = components.get('pm10', None)   # Coarse Particulate Matter (PM10)\n",
    "            nh3 = components.get('nh3', None)     # Ammonia\n",
    "\n",
    "            return main_aqi, co2, co, no, no2, o3, so2, pm25, pm10, nh3\n",
    "        \n",
    "        else:\n",
    "            return [None] * 9  # Return None for all fields if the request fails\n",
    "\n",
    "    # Applying the function to each row in the dataset\n",
    "    df[['AQI', 'CO2', 'CO', 'NO', 'NO2', 'O3', 'SO2', 'PM2.5', 'PM10', 'NH3']] = pd.DataFrame(\n",
    "        df.apply(lambda row: get_air_pollution_data(row['latitude_coordinate'], row['longitude_coordinate']), axis=1).tolist()\n",
    "    )\n",
    "\n",
    "    # units of all data is µg/m³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('dataset_with_aqi.csv', index=False)\n",
    "\n",
    "print(\"AQI data added successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
